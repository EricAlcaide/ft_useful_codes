INFO 2017-08-06 13:17:25,486 - Cifar10 data retrieved & Processed
INFO 2017-08-06 13:17:25,486 - Starting Proof of Concept
INFO 2017-08-06 13:17:25,486 - Number of layers: [1, 2, 3, 4, 5]
INFO 2017-08-06 13:17:25,486 - Number of neurons: [32, 64, 128, 256, 512, 768, 1024]
INFO 2017-08-06 13:17:25,487 - Activation: ['tanh', 'sigmoid', 'relu', 'elu', 'selu', 'linear']
INFO 2017-08-06 13:17:25,487 - Optimizer: ['sgd', 'adamax', 'rmsprop', 'adagrad', 'adadelta', 'adam', 'nadam']
INFO 2017-08-06 13:17:25,487 - Dropout: [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4]
INFO 2017-08-06 13:17:25,487 - /////////////////////////////////////////////////////
INFO 2017-08-06 13:17:25,489 - ------ GEN 1 ------
INFO 2017-08-06 13:17:25,489 - Saving the accuracy result of the training
INFO 2017-08-06 13:17:25,489 - Number of layers: 4
INFO 2017-08-06 13:17:25,489 - Number of neurons: 1024
INFO 2017-08-06 13:17:25,489 - Activation: linear
INFO 2017-08-06 13:17:25,489 - Optimizer: nadam
INFO 2017-08-06 13:17:25,489 - Dropout: 0.3
INFO 2017-08-06 13:35:05,734 - Acc @ Training: 0%
INFO 2017-08-06 13:35:05,736 - Acc @ Testing: 10.0%
INFO 2017-08-06 13:35:05,736 - --------------------------------------------------------
INFO 2017-08-06 13:35:05,736 - Saving the accuracy result of the training
INFO 2017-08-06 13:35:05,736 - Number of layers: 1
INFO 2017-08-06 13:35:05,736 - Number of neurons: 64
INFO 2017-08-06 13:35:05,736 - Activation: tanh
INFO 2017-08-06 13:35:05,736 - Optimizer: adadelta
INFO 2017-08-06 13:35:05,736 - Dropout: 0.4
INFO 2017-08-06 13:36:34,411 - Acc @ Training: 0%
INFO 2017-08-06 13:36:34,411 - Acc @ Testing: 43.24%
INFO 2017-08-06 13:36:34,411 - --------------------------------------------------------
INFO 2017-08-06 13:36:34,411 - Saving the accuracy result of the training
INFO 2017-08-06 13:36:34,411 - Number of layers: 4
INFO 2017-08-06 13:36:34,411 - Number of neurons: 32
INFO 2017-08-06 13:36:34,411 - Activation: tanh
INFO 2017-08-06 13:36:34,411 - Optimizer: adadelta
INFO 2017-08-06 13:36:34,411 - Dropout: 0.4
INFO 2017-08-06 13:37:57,274 - Acc @ Training: 0%
INFO 2017-08-06 13:37:57,274 - Acc @ Testing: 37.99%
INFO 2017-08-06 13:37:57,274 - --------------------------------------------------------
INFO 2017-08-06 13:37:57,274 - Saving the accuracy result of the training
INFO 2017-08-06 13:37:57,274 - Number of layers: 2
INFO 2017-08-06 13:37:57,274 - Number of neurons: 768
INFO 2017-08-06 13:37:57,274 - Activation: tanh
INFO 2017-08-06 13:37:57,274 - Optimizer: adagrad
INFO 2017-08-06 13:37:57,274 - Dropout: 0.2
INFO 2017-08-06 14:33:40,926 - Acc @ Training: 0%
INFO 2017-08-06 14:33:40,926 - Acc @ Testing: 48.62%
INFO 2017-08-06 14:33:40,926 - --------------------------------------------------------
INFO 2017-08-06 14:33:40,926 - Saving the accuracy result of the training
INFO 2017-08-06 14:33:40,926 - Number of layers: 4
INFO 2017-08-06 14:33:40,926 - Number of neurons: 64
INFO 2017-08-06 14:33:40,926 - Activation: selu
INFO 2017-08-06 14:33:40,926 - Optimizer: nadam
INFO 2017-08-06 14:33:40,926 - Dropout: 0.25
INFO 2017-08-06 14:36:17,611 - Acc @ Training: 0%
INFO 2017-08-06 14:36:17,611 - Acc @ Testing: 45.81%
INFO 2017-08-06 14:36:17,611 - --------------------------------------------------------
INFO 2017-08-06 14:36:17,611 - Saving the accuracy result of the training
INFO 2017-08-06 14:36:17,611 - Number of layers: 3
INFO 2017-08-06 14:36:17,611 - Number of neurons: 1024
INFO 2017-08-06 14:36:17,611 - Activation: sigmoid
INFO 2017-08-06 14:36:17,611 - Optimizer: adamax
INFO 2017-08-06 14:36:17,611 - Dropout: 0.1
INFO 2017-08-06 15:17:45,543 - Acc @ Training: 0%
INFO 2017-08-06 15:17:45,543 - Acc @ Testing: 52.63%
INFO 2017-08-06 15:17:45,543 - --------------------------------------------------------
INFO 2017-08-06 15:17:45,543 - Saving the accuracy result of the training
INFO 2017-08-06 15:17:45,543 - Number of layers: 2
INFO 2017-08-06 15:17:45,543 - Number of neurons: 64
INFO 2017-08-06 15:17:45,543 - Activation: sigmoid
INFO 2017-08-06 15:17:45,543 - Optimizer: rmsprop
INFO 2017-08-06 15:17:45,543 - Dropout: 0.4
INFO 2017-08-06 15:18:31,384 - Acc @ Training: 0%
INFO 2017-08-06 15:18:31,384 - Acc @ Testing: 39.85%
INFO 2017-08-06 15:18:31,384 - --------------------------------------------------------
INFO 2017-08-06 15:18:31,384 - Saving the accuracy result of the training
INFO 2017-08-06 15:18:31,384 - Number of layers: 1
INFO 2017-08-06 15:18:31,384 - Number of neurons: 1024
INFO 2017-08-06 15:18:31,384 - Activation: linear
INFO 2017-08-06 15:18:31,384 - Optimizer: rmsprop
INFO 2017-08-06 15:18:31,385 - Dropout: 0
INFO 2017-08-06 15:23:39,676 - Acc @ Training: 0%
INFO 2017-08-06 15:23:39,676 - Acc @ Testing: 10.0%
INFO 2017-08-06 15:23:39,676 - --------------------------------------------------------
INFO 2017-08-06 15:23:39,676 - Saving the accuracy result of the training
INFO 2017-08-06 15:23:39,676 - Number of layers: 1
INFO 2017-08-06 15:23:39,676 - Number of neurons: 512
INFO 2017-08-06 15:23:39,676 - Activation: selu
INFO 2017-08-06 15:23:39,676 - Optimizer: adamax
INFO 2017-08-06 15:23:39,676 - Dropout: 0.15
INFO 2017-08-06 15:34:14,578 - Acc @ Training: 0%
INFO 2017-08-06 15:34:14,578 - Acc @ Testing: 50.46%
INFO 2017-08-06 15:34:14,578 - --------------------------------------------------------
INFO 2017-08-06 15:34:14,578 - Saving the accuracy result of the training
INFO 2017-08-06 15:34:14,578 - Number of layers: 4
INFO 2017-08-06 15:34:14,578 - Number of neurons: 128
INFO 2017-08-06 15:34:14,578 - Activation: selu
INFO 2017-08-06 15:34:14,578 - Optimizer: nadam
INFO 2017-08-06 15:34:14,578 - Dropout: 0.05
INFO 2017-08-06 15:37:46,835 - Acc @ Training: 0%
INFO 2017-08-06 15:37:46,835 - Acc @ Testing: 49.4%
INFO 2017-08-06 15:37:46,836 - --------------------------------------------------------
INFO 2017-08-06 15:37:46,836 - Saving the accuracy result of the training
INFO 2017-08-06 15:37:46,836 - Number of layers: 4
INFO 2017-08-06 15:37:46,836 - Number of neurons: 256
INFO 2017-08-06 15:37:46,836 - Activation: relu
INFO 2017-08-06 15:37:46,836 - Optimizer: adamax
INFO 2017-08-06 15:37:46,836 - Dropout: 0.25
INFO 2017-08-06 15:44:15,296 - Acc @ Training: 0%
INFO 2017-08-06 15:44:15,296 - Acc @ Testing: 43.19%
INFO 2017-08-06 15:44:15,296 - --------------------------------------------------------
INFO 2017-08-06 15:44:15,296 - Saving the accuracy result of the training
INFO 2017-08-06 15:44:15,296 - Number of layers: 5
INFO 2017-08-06 15:44:15,296 - Number of neurons: 512
INFO 2017-08-06 15:44:15,296 - Activation: linear
INFO 2017-08-06 15:44:15,296 - Optimizer: nadam
INFO 2017-08-06 15:44:15,296 - Dropout: 0.3
INFO 2017-08-06 15:50:53,162 - Acc @ Training: 0%
INFO 2017-08-06 15:50:53,162 - Acc @ Testing: 10.0%
INFO 2017-08-06 15:50:53,162 - --------------------------------------------------------
INFO 2017-08-06 15:50:53,162 - Saving the accuracy result of the training
INFO 2017-08-06 15:50:53,162 - Number of layers: 4
INFO 2017-08-06 15:50:53,162 - Number of neurons: 256
INFO 2017-08-06 15:50:53,162 - Activation: elu
INFO 2017-08-06 15:50:53,162 - Optimizer: adadelta
INFO 2017-08-06 15:50:53,163 - Dropout: 0.05
INFO 2017-08-06 15:55:37,316 - Acc @ Training: 0%
INFO 2017-08-06 15:55:37,316 - Acc @ Testing: 48.38%
INFO 2017-08-06 15:55:37,316 - --------------------------------------------------------
INFO 2017-08-06 15:55:37,316 - Saving the accuracy result of the training
INFO 2017-08-06 15:55:37,316 - Number of layers: 4
INFO 2017-08-06 15:55:37,316 - Number of neurons: 256
INFO 2017-08-06 15:55:37,316 - Activation: elu
INFO 2017-08-06 15:55:37,316 - Optimizer: adam
INFO 2017-08-06 15:55:37,316 - Dropout: 0.05
INFO 2017-08-06 16:03:16,091 - Acc @ Training: 0%
INFO 2017-08-06 16:03:16,091 - Acc @ Testing: 50.65%
INFO 2017-08-06 16:03:16,092 - --------------------------------------------------------
INFO 2017-08-06 16:03:16,092 - Saving the accuracy result of the training
INFO 2017-08-06 16:03:16,092 - Number of layers: 2
INFO 2017-08-06 16:03:16,092 - Number of neurons: 768
INFO 2017-08-06 16:03:16,092 - Activation: tanh
INFO 2017-08-06 16:03:16,092 - Optimizer: nadam
INFO 2017-08-06 16:03:16,092 - Dropout: 0.3
INFO 2017-08-06 16:20:35,963 - Acc @ Training: 0%
INFO 2017-08-06 16:20:35,963 - Acc @ Testing: 14.32%
INFO 2017-08-06 16:20:35,963 - --------------------------------------------------------
INFO 2017-08-06 16:20:35,963 - Saving the accuracy result of the training
INFO 2017-08-06 16:20:35,963 - Number of layers: 3
INFO 2017-08-06 16:20:35,963 - Number of neurons: 64
INFO 2017-08-06 16:20:35,963 - Activation: tanh
INFO 2017-08-06 16:20:35,963 - Optimizer: adam
INFO 2017-08-06 16:20:35,963 - Dropout: 0.1
INFO 2017-08-06 16:22:42,629 - Acc @ Training: 0%
INFO 2017-08-06 16:22:42,629 - Acc @ Testing: 39.88%
INFO 2017-08-06 16:22:42,629 - --------------------------------------------------------
INFO 2017-08-06 16:22:42,629 - Saving the accuracy result of the training
INFO 2017-08-06 16:22:42,629 - Number of layers: 4
INFO 2017-08-06 16:22:42,629 - Number of neurons: 32
INFO 2017-08-06 16:22:42,629 - Activation: linear
INFO 2017-08-06 16:22:42,629 - Optimizer: nadam
INFO 2017-08-06 16:22:42,629 - Dropout: 0.15
INFO 2017-08-06 16:23:50,012 - Acc @ Training: 0%
INFO 2017-08-06 16:23:50,012 - Acc @ Testing: 37.79%
INFO 2017-08-06 16:23:50,012 - --------------------------------------------------------
INFO 2017-08-06 16:23:50,013 - Saving the accuracy result of the training
INFO 2017-08-06 16:23:50,013 - Number of layers: 1
INFO 2017-08-06 16:23:50,013 - Number of neurons: 32
INFO 2017-08-06 16:23:50,013 - Activation: selu
INFO 2017-08-06 16:23:50,013 - Optimizer: adadelta
INFO 2017-08-06 16:23:50,013 - Dropout: 0.25
INFO 2017-08-06 16:24:17,630 - Acc @ Training: 0%
INFO 2017-08-06 16:24:17,630 - Acc @ Testing: 37.8%
INFO 2017-08-06 16:24:17,630 - --------------------------------------------------------
INFO 2017-08-06 16:24:17,630 - Saving the accuracy result of the training
INFO 2017-08-06 16:24:17,630 - Number of layers: 3
INFO 2017-08-06 16:24:17,630 - Number of neurons: 32
INFO 2017-08-06 16:24:17,630 - Activation: elu
INFO 2017-08-06 16:24:17,630 - Optimizer: sgd
INFO 2017-08-06 16:24:17,630 - Dropout: 0
INFO 2017-08-06 16:24:52,043 - Acc @ Training: 0%
INFO 2017-08-06 16:24:52,043 - Acc @ Testing: 43.1%
INFO 2017-08-06 16:24:52,043 - --------------------------------------------------------
INFO 2017-08-06 16:24:52,043 - Saving the accuracy result of the training
INFO 2017-08-06 16:24:52,043 - Number of layers: 1
INFO 2017-08-06 16:24:52,043 - Number of neurons: 128
INFO 2017-08-06 16:24:52,043 - Activation: selu
INFO 2017-08-06 16:24:52,043 - Optimizer: nadam
INFO 2017-08-06 16:24:52,043 - Dropout: 0.25
INFO 2017-08-06 16:28:13,354 - Acc @ Training: 0%
INFO 2017-08-06 16:28:13,355 - Acc @ Testing: 47.38%
INFO 2017-08-06 16:28:13,355 - --------------------------------------------------------
INFO 2017-08-06 16:28:13,355 - Generation Average: 38.0245
INFO 2017-08-06 16:28:13,355 - --------------------------------------------------------
INFO 2017-08-06 16:28:13,361 - Parents: [{'activation': 'sigmoid', 'dropout': 0.1, 'nb_neurons': 1024, 'optimizer': 'adamax', 'nb_layers': 3}, {'activation': 'elu', 'dropout': 0.05, 'nb_neurons': 256, 'optimizer': 'adam', 'nb_layers': 4}, {'activation': 'selu', 'dropout': 0.15, 'nb_neurons': 512, 'optimizer': 'adamax', 'nb_layers': 1}, {'activation': 'selu', 'dropout': 0.05, 'nb_neurons': 128, 'optimizer': 'nadam', 'nb_layers': 4}]
INFO 2017-08-06 16:28:13,361 - *************************************************
INFO 2017-08-06 16:28:13,361 - ------ GEN 2 ------
INFO 2017-08-06 16:28:13,361 - Saving the accuracy result of the training
INFO 2017-08-06 16:28:13,361 - Number of layers: 3
INFO 2017-08-06 16:28:13,361 - Number of neurons: 1024
INFO 2017-08-06 16:28:13,361 - Activation: sigmoid
INFO 2017-08-06 16:28:13,361 - Optimizer: adamax
INFO 2017-08-06 16:28:13,361 - Dropout: 0.1
INFO 2017-08-06 17:31:21,812 - Acc @ Training: 0%
INFO 2017-08-06 17:31:21,813 - Acc @ Testing: 55.16%
INFO 2017-08-06 17:31:21,813 - --------------------------------------------------------
INFO 2017-08-06 17:31:21,813 - Saving the accuracy result of the training
INFO 2017-08-06 17:31:21,813 - Number of layers: 4
INFO 2017-08-06 17:31:21,813 - Number of neurons: 256
INFO 2017-08-06 17:31:21,813 - Activation: elu
INFO 2017-08-06 17:31:21,813 - Optimizer: adam
INFO 2017-08-06 17:31:21,813 - Dropout: 0.05
INFO 2017-08-06 17:35:36,551 - Acc @ Training: 0%
INFO 2017-08-06 17:35:36,551 - Acc @ Testing: 51.13%
INFO 2017-08-06 17:35:36,551 - --------------------------------------------------------
INFO 2017-08-06 17:35:36,551 - Saving the accuracy result of the training
INFO 2017-08-06 17:35:36,551 - Number of layers: 1
INFO 2017-08-06 17:35:36,551 - Number of neurons: 512
INFO 2017-08-06 17:35:36,552 - Activation: selu
INFO 2017-08-06 17:35:36,552 - Optimizer: adamax
INFO 2017-08-06 17:35:36,552 - Dropout: 0.15
INFO 2017-08-06 17:49:14,343 - Acc @ Training: 0%
INFO 2017-08-06 17:49:14,343 - Acc @ Testing: 52.52%
INFO 2017-08-06 17:49:14,343 - --------------------------------------------------------
INFO 2017-08-06 17:49:14,343 - Saving the accuracy result of the training
INFO 2017-08-06 17:49:14,343 - Number of layers: 4
INFO 2017-08-06 17:49:14,343 - Number of neurons: 128
INFO 2017-08-06 17:49:14,343 - Activation: selu
INFO 2017-08-06 17:49:14,343 - Optimizer: nadam
INFO 2017-08-06 17:49:14,343 - Dropout: 0.05
INFO 2017-08-06 17:53:25,822 - Acc @ Training: 0%
INFO 2017-08-06 17:53:25,822 - Acc @ Testing: 47.24%
INFO 2017-08-06 17:53:25,822 - --------------------------------------------------------
INFO 2017-08-06 17:53:25,822 - Saving the accuracy result of the training
INFO 2017-08-06 17:53:25,822 - Number of layers: 4
INFO 2017-08-06 17:53:25,822 - Number of neurons: 512
INFO 2017-08-06 17:53:25,822 - Activation: selu
INFO 2017-08-06 17:53:25,823 - Optimizer: nadam
INFO 2017-08-06 17:53:25,823 - Dropout: 0.05
INFO 2017-08-06 17:59:26,993 - Acc @ Training: 0%
INFO 2017-08-06 17:59:26,993 - Acc @ Testing: 10.0%
INFO 2017-08-06 17:59:26,993 - --------------------------------------------------------
INFO 2017-08-06 17:59:26,993 - Saving the accuracy result of the training
INFO 2017-08-06 17:59:26,993 - Number of layers: 4
INFO 2017-08-06 17:59:26,993 - Number of neurons: 256
INFO 2017-08-06 17:59:26,993 - Activation: elu
INFO 2017-08-06 17:59:26,993 - Optimizer: adam
INFO 2017-08-06 17:59:26,993 - Dropout: 0.05
INFO 2017-08-06 18:05:48,572 - Acc @ Training: 0%
INFO 2017-08-06 18:05:48,572 - Acc @ Testing: 51.71%
INFO 2017-08-06 18:05:48,572 - --------------------------------------------------------
INFO 2017-08-06 18:05:48,572 - Saving the accuracy result of the training
INFO 2017-08-06 18:05:48,572 - Number of layers: 4
INFO 2017-08-06 18:05:48,572 - Number of neurons: 128
INFO 2017-08-06 18:05:48,572 - Activation: selu
INFO 2017-08-06 18:05:48,572 - Optimizer: adam
INFO 2017-08-06 18:05:48,572 - Dropout: 0.05
INFO 2017-08-06 18:09:37,395 - Acc @ Training: 0%
INFO 2017-08-06 18:09:37,395 - Acc @ Testing: 49.94%
INFO 2017-08-06 18:09:37,395 - --------------------------------------------------------
INFO 2017-08-06 18:09:37,395 - Saving the accuracy result of the training
INFO 2017-08-06 18:09:37,395 - Number of layers: 3
INFO 2017-08-06 18:09:37,395 - Number of neurons: 1024
INFO 2017-08-06 18:09:37,395 - Activation: sigmoid
INFO 2017-08-06 18:09:37,395 - Optimizer: adam
INFO 2017-08-06 18:09:37,395 - Dropout: 0.1
INFO 2017-08-06 19:07:52,439 - Acc @ Training: 0%
INFO 2017-08-06 19:07:52,441 - Acc @ Testing: 46.57%
INFO 2017-08-06 19:07:52,441 - --------------------------------------------------------
INFO 2017-08-06 19:07:52,441 - Saving the accuracy result of the training
INFO 2017-08-06 19:07:52,441 - Number of layers: 4
INFO 2017-08-06 19:07:52,441 - Number of neurons: 256
INFO 2017-08-06 19:07:52,441 - Activation: elu
INFO 2017-08-06 19:07:52,441 - Optimizer: nadam
INFO 2017-08-06 19:07:52,441 - Dropout: 0.05
INFO 2017-08-06 19:14:47,851 - Acc @ Training: 0%
INFO 2017-08-06 19:14:47,851 - Acc @ Testing: 48.58%
INFO 2017-08-06 19:14:47,851 - --------------------------------------------------------
INFO 2017-08-06 19:14:47,851 - Saving the accuracy result of the training
INFO 2017-08-06 19:14:47,852 - Number of layers: 4
INFO 2017-08-06 19:14:47,852 - Number of neurons: 1024
INFO 2017-08-06 19:14:47,852 - Activation: sigmoid
INFO 2017-08-06 19:14:47,852 - Optimizer: adamax
INFO 2017-08-06 19:14:47,852 - Dropout: 0.05
INFO 2017-08-06 20:33:53,527 - Acc @ Training: 0%
INFO 2017-08-06 20:33:53,528 - Acc @ Testing: 55.29%
INFO 2017-08-06 20:33:53,528 - --------------------------------------------------------
INFO 2017-08-06 20:33:53,529 - Saving the accuracy result of the training
INFO 2017-08-06 20:33:53,529 - Number of layers: 4
INFO 2017-08-06 20:33:53,529 - Number of neurons: 128
INFO 2017-08-06 20:33:53,529 - Activation: selu
INFO 2017-08-06 20:33:53,529 - Optimizer: nadam
INFO 2017-08-06 20:33:53,529 - Dropout: 0.05
INFO 2017-08-06 20:37:35,451 - Acc @ Training: 0%
INFO 2017-08-06 20:37:35,451 - Acc @ Testing: 47.08%
INFO 2017-08-06 20:37:35,451 - --------------------------------------------------------
INFO 2017-08-06 20:37:35,451 - Saving the accuracy result of the training
INFO 2017-08-06 20:37:35,451 - Number of layers: 4
INFO 2017-08-06 20:37:35,451 - Number of neurons: 256
INFO 2017-08-06 20:37:35,451 - Activation: selu
INFO 2017-08-06 20:37:35,451 - Optimizer: nadam
INFO 2017-08-06 20:37:35,452 - Dropout: 0.05
INFO 2017-08-06 20:45:14,220 - Acc @ Training: 0%
INFO 2017-08-06 20:45:14,220 - Acc @ Testing: 46.18%
INFO 2017-08-06 20:45:14,220 - --------------------------------------------------------
INFO 2017-08-06 20:45:14,220 - Saving the accuracy result of the training
INFO 2017-08-06 20:45:14,220 - Number of layers: 3
INFO 2017-08-06 20:45:14,220 - Number of neurons: 1024
INFO 2017-08-06 20:45:14,220 - Activation: selu
INFO 2017-08-06 20:45:14,220 - Optimizer: adamax
INFO 2017-08-06 20:45:14,220 - Dropout: 0.1
INFO 2017-08-06 20:57:49,311 - Acc @ Training: 0%
INFO 2017-08-06 20:57:49,311 - Acc @ Testing: 10.0%
INFO 2017-08-06 20:57:49,311 - --------------------------------------------------------
INFO 2017-08-06 20:57:49,311 - Saving the accuracy result of the training
INFO 2017-08-06 20:57:49,312 - Number of layers: 1
INFO 2017-08-06 20:57:49,312 - Number of neurons: 512
INFO 2017-08-06 20:57:49,312 - Activation: selu
INFO 2017-08-06 20:57:49,312 - Optimizer: adamax
INFO 2017-08-06 20:57:49,312 - Dropout: 0.15
INFO 2017-08-06 21:11:51,464 - Acc @ Training: 0%
INFO 2017-08-06 21:11:51,464 - Acc @ Testing: 51.98%
INFO 2017-08-06 21:11:51,464 - --------------------------------------------------------
INFO 2017-08-06 21:11:51,464 - Saving the accuracy result of the training
INFO 2017-08-06 21:11:51,464 - Number of layers: 1
INFO 2017-08-06 21:11:51,464 - Number of neurons: 1024
INFO 2017-08-06 21:11:51,464 - Activation: selu
INFO 2017-08-06 21:11:51,464 - Optimizer: adamax
INFO 2017-08-06 21:11:51,464 - Dropout: 0.1
INFO 2017-08-06 21:26:54,589 - Acc @ Training: 0%
INFO 2017-08-06 21:26:54,589 - Acc @ Testing: 42.78%
INFO 2017-08-06 21:26:54,589 - --------------------------------------------------------
INFO 2017-08-06 21:26:54,589 - Saving the accuracy result of the training
INFO 2017-08-06 21:26:54,589 - Number of layers: 4
INFO 2017-08-06 21:26:54,589 - Number of neurons: 128
INFO 2017-08-06 21:26:54,589 - Activation: selu
INFO 2017-08-06 21:26:54,589 - Optimizer: adam
INFO 2017-08-06 21:26:54,589 - Dropout: 0.05
INFO 2017-08-06 21:31:06,250 - Acc @ Training: 0%
INFO 2017-08-06 21:31:06,250 - Acc @ Testing: 50.48%
INFO 2017-08-06 21:31:06,250 - --------------------------------------------------------
INFO 2017-08-06 21:31:06,250 - Saving the accuracy result of the training
INFO 2017-08-06 21:31:06,250 - Number of layers: 1
INFO 2017-08-06 21:31:06,251 - Number of neurons: 256
INFO 2017-08-06 21:31:06,251 - Activation: selu
INFO 2017-08-06 21:31:06,251 - Optimizer: adamax
INFO 2017-08-06 21:31:06,251 - Dropout: 0.05
INFO 2017-08-06 21:35:47,898 - Acc @ Training: 0%
INFO 2017-08-06 21:35:47,898 - Acc @ Testing: 51.03%
INFO 2017-08-06 21:35:47,899 - --------------------------------------------------------
INFO 2017-08-06 21:35:47,899 - Saving the accuracy result of the training
INFO 2017-08-06 21:35:47,899 - Number of layers: 4
INFO 2017-08-06 21:35:47,899 - Number of neurons: 128
INFO 2017-08-06 21:35:47,899 - Activation: selu
INFO 2017-08-06 21:35:47,899 - Optimizer: nadam
INFO 2017-08-06 21:35:47,899 - Dropout: 0.05
INFO 2017-08-06 21:40:02,227 - Acc @ Training: 0%
INFO 2017-08-06 21:40:02,227 - Acc @ Testing: 48.3%
INFO 2017-08-06 21:40:02,227 - --------------------------------------------------------
INFO 2017-08-06 21:40:02,227 - Saving the accuracy result of the training
INFO 2017-08-06 21:40:02,227 - Number of layers: 4
INFO 2017-08-06 21:40:02,227 - Number of neurons: 256
INFO 2017-08-06 21:40:02,227 - Activation: elu
INFO 2017-08-06 21:40:02,227 - Optimizer: nadam
INFO 2017-08-06 21:40:02,227 - Dropout: 0.05
INFO 2017-08-06 21:46:23,241 - Acc @ Training: 0%
INFO 2017-08-06 21:46:23,241 - Acc @ Testing: 48.46%
INFO 2017-08-06 21:46:23,241 - --------------------------------------------------------
INFO 2017-08-06 21:46:23,241 - Saving the accuracy result of the training
INFO 2017-08-06 21:46:23,241 - Number of layers: 3
INFO 2017-08-06 21:46:23,241 - Number of neurons: 256
INFO 2017-08-06 21:46:23,241 - Activation: elu
INFO 2017-08-06 21:46:23,241 - Optimizer: adam
INFO 2017-08-06 21:46:23,241 - Dropout: 0.05
INFO 2017-08-06 21:52:52,032 - Acc @ Training: 0%
INFO 2017-08-06 21:52:52,032 - Acc @ Testing: 52.78%
INFO 2017-08-06 21:52:52,032 - --------------------------------------------------------
INFO 2017-08-06 21:52:52,032 - Generation Average: 45.8605
INFO 2017-08-06 21:52:52,032 - --------------------------------------------------------
INFO 2017-08-07 23:42:45,040 - Parents: [{'nb_layers': 4, 'nb_neurons': 1024, 'dropout': 0.05, 'activation': 'sigmoid', 'optimizer': 'adamax'}, {'nb_layers': 3, 'nb_neurons': 1024, 'dropout': 0.1, 'activation': 'sigmoid', 'optimizer': 'adamax'}, {'nb_layers': 3, 'nb_neurons': 256, 'dropout': 0.05, 'activation': 'elu', 'optimizer': 'adam'}, {'nb_layers': 1, 'nb_neurons': 512, 'dropout': 0.15, 'activation': 'selu', 'optimizer': 'adamax'}]
INFO 2017-08-07 23:42:45,040 - *************************************************
INFO 2017-08-07 23:42:45,041 - ------ GEN 3 ------
INFO 2017-08-07 23:42:45,041 - Saving the accuracy result of the training
INFO 2017-08-07 23:42:45,041 - Number of layers: 4
INFO 2017-08-07 23:42:45,041 - Number of neurons: 1024
INFO 2017-08-07 23:42:45,041 - Activation: sigmoid
INFO 2017-08-07 23:42:45,041 - Optimizer: adamax
INFO 2017-08-07 23:42:45,041 - Dropout: 0.05
INFO 2017-08-08 00:51:17,637 - Acc @ Training: 0%
INFO 2017-08-08 00:51:17,640 - Acc @ Testing: 53.87%
INFO 2017-08-08 00:51:17,640 - --------------------------------------------------------
INFO 2017-08-08 00:51:17,640 - Saving the accuracy result of the training
INFO 2017-08-08 00:51:17,640 - Number of layers: 3
INFO 2017-08-08 00:51:17,640 - Number of neurons: 1024
INFO 2017-08-08 00:51:17,640 - Activation: sigmoid
INFO 2017-08-08 00:51:17,640 - Optimizer: adamax
INFO 2017-08-08 00:51:17,640 - Dropout: 0.1
INFO 2017-08-08 02:04:00,084 - Acc @ Training: 0%
INFO 2017-08-08 02:04:00,085 - Acc @ Testing: 55.13%
INFO 2017-08-08 02:04:00,085 - --------------------------------------------------------
INFO 2017-08-08 02:04:00,085 - Saving the accuracy result of the training
INFO 2017-08-08 02:04:00,085 - Number of layers: 3
INFO 2017-08-08 02:04:00,085 - Number of neurons: 256
INFO 2017-08-08 02:04:00,085 - Activation: elu
INFO 2017-08-08 02:04:00,085 - Optimizer: sgd
INFO 2017-08-08 02:04:00,085 - Dropout: 0.05
INFO 2017-08-08 02:05:53,926 - Acc @ Training: 0%
INFO 2017-08-08 02:05:53,926 - Acc @ Testing: 34.88%
INFO 2017-08-08 02:05:53,927 - --------------------------------------------------------
INFO 2017-08-08 02:05:53,927 - Saving the accuracy result of the training
INFO 2017-08-08 02:05:53,927 - Number of layers: 1
INFO 2017-08-08 02:05:53,927 - Number of neurons: 512
INFO 2017-08-08 02:05:53,927 - Activation: selu
INFO 2017-08-08 02:05:53,927 - Optimizer: adamax
INFO 2017-08-08 02:05:53,927 - Dropout: 0.15
INFO 2017-08-08 02:18:14,624 - Acc @ Training: 0%
INFO 2017-08-08 02:18:14,624 - Acc @ Testing: 52.56%
INFO 2017-08-08 02:18:14,624 - --------------------------------------------------------
INFO 2017-08-08 02:18:14,624 - Saving the accuracy result of the training
INFO 2017-08-08 02:18:14,624 - Number of layers: 4
INFO 2017-08-08 02:18:14,625 - Number of neurons: 512
INFO 2017-08-08 02:18:14,625 - Activation: sigmoid
INFO 2017-08-08 02:18:14,625 - Optimizer: adamax
INFO 2017-08-08 02:18:14,625 - Dropout: 0.05
INFO 2017-08-08 02:39:37,336 - Acc @ Training: 0%
INFO 2017-08-08 02:39:37,336 - Acc @ Testing: 52.3%
INFO 2017-08-08 02:39:37,337 - --------------------------------------------------------
INFO 2017-08-08 02:39:37,337 - Saving the accuracy result of the training
INFO 2017-08-08 02:39:37,337 - Number of layers: 1
INFO 2017-08-08 02:39:37,337 - Number of neurons: 512
INFO 2017-08-08 02:39:37,337 - Activation: selu
INFO 2017-08-08 02:39:37,337 - Optimizer: adamax
INFO 2017-08-08 02:39:37,337 - Dropout: 0.15
INFO 2017-08-08 02:52:49,877 - Acc @ Training: 0%
INFO 2017-08-08 02:52:49,877 - Acc @ Testing: 50.54%
INFO 2017-08-08 02:52:49,877 - --------------------------------------------------------
INFO 2017-08-08 02:52:49,877 - Saving the accuracy result of the training
INFO 2017-08-08 02:52:49,877 - Number of layers: 3
INFO 2017-08-08 02:52:49,877 - Number of neurons: 512
INFO 2017-08-08 02:52:49,877 - Activation: elu
INFO 2017-08-08 02:52:49,877 - Optimizer: sgd
INFO 2017-08-08 02:52:49,877 - Dropout: 0.15
INFO 2017-08-08 03:05:54,024 - Acc @ Training: 0%
INFO 2017-08-08 03:05:54,024 - Acc @ Testing: 48.92%
INFO 2017-08-08 03:05:54,024 - --------------------------------------------------------
INFO 2017-08-08 03:05:54,024 - Saving the accuracy result of the training
INFO 2017-08-08 03:05:54,024 - Number of layers: 4
INFO 2017-08-08 03:05:54,024 - Number of neurons: 512
INFO 2017-08-08 03:05:54,024 - Activation: sigmoid
INFO 2017-08-08 03:05:54,024 - Optimizer: adamax
INFO 2017-08-08 03:05:54,024 - Dropout: 0.05
INFO 2017-08-08 03:26:06,918 - Acc @ Training: 0%
INFO 2017-08-08 03:26:06,918 - Acc @ Testing: 52.71%
INFO 2017-08-08 03:26:06,918 - --------------------------------------------------------
INFO 2017-08-08 03:26:06,918 - Saving the accuracy result of the training
INFO 2017-08-08 03:26:06,918 - Number of layers: 3
INFO 2017-08-08 03:26:06,918 - Number of neurons: 512
INFO 2017-08-08 03:26:06,918 - Activation: elu
INFO 2017-08-08 03:26:06,918 - Optimizer: sgd
INFO 2017-08-08 03:26:06,918 - Dropout: 0.15
INFO 2017-08-08 03:32:40,926 - Acc @ Training: 0%
INFO 2017-08-08 03:32:40,926 - Acc @ Testing: 45.85%
INFO 2017-08-08 03:32:40,926 - --------------------------------------------------------
INFO 2017-08-08 03:32:40,926 - Saving the accuracy result of the training
INFO 2017-08-08 03:32:40,926 - Number of layers: 3
INFO 2017-08-08 03:32:40,926 - Number of neurons: 1024
INFO 2017-08-08 03:32:40,927 - Activation: sigmoid
INFO 2017-08-08 03:32:40,927 - Optimizer: sgd
INFO 2017-08-08 03:32:40,927 - Dropout: 0.1
INFO 2017-08-08 06:17:23,649 - Acc @ Training: 0%
INFO 2017-08-08 06:17:23,649 - Acc @ Testing: 45.26%
INFO 2017-08-08 06:17:23,649 - --------------------------------------------------------
INFO 2017-08-08 06:17:23,649 - Saving the accuracy result of the training
INFO 2017-08-08 06:17:23,649 - Number of layers: 1
INFO 2017-08-08 06:17:23,649 - Number of neurons: 512
INFO 2017-08-08 06:17:23,649 - Activation: selu
INFO 2017-08-08 06:17:23,649 - Optimizer: adamax
INFO 2017-08-08 06:17:23,650 - Dropout: 0.05
INFO 2017-08-08 06:26:10,535 - Acc @ Training: 0%
INFO 2017-08-08 06:26:10,535 - Acc @ Testing: 52.19%
INFO 2017-08-08 06:26:10,535 - --------------------------------------------------------
INFO 2017-08-08 06:26:10,536 - Saving the accuracy result of the training
INFO 2017-08-08 06:26:10,536 - Number of layers: 3
INFO 2017-08-08 06:26:10,536 - Number of neurons: 1024
INFO 2017-08-08 06:26:10,536 - Activation: sigmoid
INFO 2017-08-08 06:26:10,536 - Optimizer: adamax
INFO 2017-08-08 06:26:10,536 - Dropout: 0.05
INFO 2017-08-08 06:55:46,189 - Acc @ Training: 0%
INFO 2017-08-08 06:55:46,189 - Acc @ Testing: 52.54%
INFO 2017-08-08 06:55:46,190 - --------------------------------------------------------
INFO 2017-08-08 06:55:46,190 - Saving the accuracy result of the training
INFO 2017-08-08 06:55:46,190 - Number of layers: 3
INFO 2017-08-08 06:55:46,190 - Number of neurons: 1024
INFO 2017-08-08 06:55:46,190 - Activation: selu
INFO 2017-08-08 06:55:46,190 - Optimizer: adamax
INFO 2017-08-08 06:55:46,190 - Dropout: 0.15
INFO 2017-08-08 07:05:29,947 - Acc @ Training: 0%
INFO 2017-08-08 07:05:29,947 - Acc @ Testing: 10.0%
INFO 2017-08-08 07:05:29,947 - --------------------------------------------------------
INFO 2017-08-08 07:05:29,947 - Saving the accuracy result of the training
INFO 2017-08-08 07:05:29,947 - Number of layers: 3
INFO 2017-08-08 07:05:29,947 - Number of neurons: 1024
INFO 2017-08-08 07:05:29,947 - Activation: sigmoid
INFO 2017-08-08 07:05:29,947 - Optimizer: adamax
INFO 2017-08-08 07:05:29,947 - Dropout: 0.05
INFO 2017-08-08 07:43:55,949 - Acc @ Training: 0%
INFO 2017-08-08 07:43:55,949 - Acc @ Testing: 53.3%
INFO 2017-08-08 07:43:55,949 - --------------------------------------------------------
INFO 2017-08-08 07:43:55,950 - Saving the accuracy result of the training
INFO 2017-08-08 07:43:55,950 - Number of layers: 1
INFO 2017-08-08 07:43:55,950 - Number of neurons: 512
INFO 2017-08-08 07:43:55,950 - Activation: elu
INFO 2017-08-08 07:43:55,950 - Optimizer: sgd
INFO 2017-08-08 07:43:55,950 - Dropout: 0.05
INFO 2017-08-08 07:48:39,833 - Acc @ Training: 0%
INFO 2017-08-08 07:48:39,833 - Acc @ Testing: 44.06%
INFO 2017-08-08 07:48:39,833 - --------------------------------------------------------
INFO 2017-08-08 07:48:39,833 - Saving the accuracy result of the training
INFO 2017-08-08 07:48:39,833 - Number of layers: 1
INFO 2017-08-08 07:48:39,833 - Number of neurons: 512
INFO 2017-08-08 07:48:39,833 - Activation: selu
INFO 2017-08-08 07:48:39,833 - Optimizer: adamax
INFO 2017-08-08 07:48:39,833 - Dropout: 0.15
INFO 2017-08-08 08:01:25,158 - Acc @ Training: 0%
INFO 2017-08-08 08:01:25,158 - Acc @ Testing: 52.17%
INFO 2017-08-08 08:01:25,158 - --------------------------------------------------------
INFO 2017-08-08 08:01:25,158 - Saving the accuracy result of the training
INFO 2017-08-08 08:01:25,158 - Number of layers: 4
INFO 2017-08-08 08:01:25,158 - Number of neurons: 1024
INFO 2017-08-08 08:01:25,158 - Activation: sigmoid
INFO 2017-08-08 08:01:25,158 - Optimizer: adamax
INFO 2017-08-08 08:01:25,158 - Dropout: 0.1
INFO 2017-08-08 09:22:31,217 - Acc @ Training: 0%
INFO 2017-08-08 09:22:31,220 - Acc @ Testing: 53.34%
INFO 2017-08-08 09:22:31,220 - --------------------------------------------------------
INFO 2017-08-08 09:22:31,220 - Saving the accuracy result of the training
INFO 2017-08-08 09:22:31,220 - Number of layers: 3
INFO 2017-08-08 09:22:31,220 - Number of neurons: 256
INFO 2017-08-08 09:22:31,220 - Activation: selu
INFO 2017-08-08 09:22:31,221 - Optimizer: adamax
INFO 2017-08-08 09:22:31,221 - Dropout: 0.15
INFO 2017-08-08 09:31:08,474 - Acc @ Training: 0%
INFO 2017-08-08 09:31:08,474 - Acc @ Testing: 54.65%
INFO 2017-08-08 09:31:08,474 - --------------------------------------------------------
INFO 2017-08-08 09:31:08,474 - Saving the accuracy result of the training
INFO 2017-08-08 09:31:08,474 - Number of layers: 1
INFO 2017-08-08 09:31:08,474 - Number of neurons: 512
INFO 2017-08-08 09:31:08,474 - Activation: sigmoid
INFO 2017-08-08 09:31:08,474 - Optimizer: adamax
INFO 2017-08-08 09:31:08,474 - Dropout: 0.15
INFO 2017-08-08 09:51:35,185 - Acc @ Training: 0%
INFO 2017-08-08 09:51:35,185 - Acc @ Testing: 52.68%
INFO 2017-08-08 09:51:35,185 - --------------------------------------------------------
INFO 2017-08-08 09:51:35,186 - Saving the accuracy result of the training
INFO 2017-08-08 09:51:35,186 - Number of layers: 1
INFO 2017-08-08 09:51:35,186 - Number of neurons: 256
INFO 2017-08-08 09:51:35,186 - Activation: elu
INFO 2017-08-08 09:51:35,186 - Optimizer: adamax
INFO 2017-08-08 09:51:35,186 - Dropout: 0.15
INFO 2017-08-08 09:56:15,535 - Acc @ Training: 0%
INFO 2017-08-08 09:56:15,535 - Acc @ Testing: 51.17%
INFO 2017-08-08 09:56:15,535 - --------------------------------------------------------
INFO 2017-08-08 09:56:15,535 - Generation Average: 48.406
INFO 2017-08-08 09:56:15,535 - --------------------------------------------------------
INFO 2017-08-08 11:39:07,438 - Parents: [{'nb_layers': 3, 'nb_neurons': 256, 'optimizer': 'adamax', 'dropout': 0.15, 'activation': 'selu'}, {'nb_layers': 4, 'nb_neurons': 1024, 'optimizer': 'adamax', 'dropout': 0.05, 'activation': 'sigmoid'}, {'nb_layers': 4, 'nb_neurons': 1024, 'optimizer': 'adamax', 'dropout': 0.1, 'activation': 'sigmoid'}, {'nb_layers': 3, 'nb_neurons': 1024, 'optimizer': 'adamax', 'dropout': 0.05, 'activation': 'sigmoid'}]
INFO 2017-08-08 11:39:07,438 - *************************************************
INFO 2017-08-08 11:39:07,439 - ------ GEN 4 ------
INFO 2017-08-08 11:39:07,439 - Saving the accuracy result of the training
INFO 2017-08-08 11:39:07,439 - Number of layers: 3
INFO 2017-08-08 11:39:07,439 - Number of neurons: 256
INFO 2017-08-08 11:39:07,439 - Activation: selu
INFO 2017-08-08 11:39:07,439 - Optimizer: adamax
INFO 2017-08-08 11:39:07,439 - Dropout: 0.15
INFO 2017-08-08 11:44:34,887 - Acc @ Training: 0%
INFO 2017-08-08 11:44:34,891 - Acc @ Testing: 54.87%
INFO 2017-08-08 11:44:34,891 - --------------------------------------------------------
INFO 2017-08-08 11:44:34,891 - Saving the accuracy result of the training
INFO 2017-08-08 11:44:34,891 - Number of layers: 4
INFO 2017-08-08 11:44:34,891 - Number of neurons: 1024
INFO 2017-08-08 11:44:34,891 - Activation: sigmoid
INFO 2017-08-08 11:44:34,891 - Optimizer: adamax
INFO 2017-08-08 11:44:34,891 - Dropout: 0.05
INFO 2017-08-08 11:59:49,926 - Acc @ Training: 0%
INFO 2017-08-08 11:59:49,926 - Acc @ Testing: 53.68%
INFO 2017-08-08 11:59:49,926 - --------------------------------------------------------
INFO 2017-08-08 11:59:49,926 - Saving the accuracy result of the training
INFO 2017-08-08 11:59:49,926 - Number of layers: 4
INFO 2017-08-08 11:59:49,927 - Number of neurons: 1024
INFO 2017-08-08 11:59:49,927 - Activation: relu
INFO 2017-08-08 11:59:49,927 - Optimizer: adamax
INFO 2017-08-08 11:59:49,927 - Dropout: 0.1
INFO 2017-08-08 12:10:50,664 - Acc @ Training: 0%
INFO 2017-08-08 12:10:50,664 - Acc @ Testing: 52.07%
INFO 2017-08-08 12:10:50,664 - --------------------------------------------------------
INFO 2017-08-08 12:10:50,664 - Saving the accuracy result of the training
INFO 2017-08-08 12:10:50,664 - Number of layers: 3
INFO 2017-08-08 12:10:50,664 - Number of neurons: 1024
INFO 2017-08-08 12:10:50,664 - Activation: sigmoid
INFO 2017-08-08 12:10:50,664 - Optimizer: adamax
INFO 2017-08-08 12:10:50,664 - Dropout: 0.15
INFO 2017-08-08 12:29:28,109 - Acc @ Training: 0%
INFO 2017-08-08 12:29:28,109 - Acc @ Testing: 54.33%
INFO 2017-08-08 12:29:28,109 - --------------------------------------------------------
INFO 2017-08-08 12:29:28,109 - Saving the accuracy result of the training
INFO 2017-08-08 12:29:28,109 - Number of layers: 3
INFO 2017-08-08 12:29:28,109 - Number of neurons: 256
INFO 2017-08-08 12:29:28,109 - Activation: sigmoid
INFO 2017-08-08 12:29:28,109 - Optimizer: adamax
INFO 2017-08-08 12:29:28,109 - Dropout: 0.15
INFO 2017-08-08 12:34:24,791 - Acc @ Training: 0%
INFO 2017-08-08 12:34:24,791 - Acc @ Testing: 53.56%
INFO 2017-08-08 12:34:24,791 - --------------------------------------------------------
INFO 2017-08-08 12:34:24,791 - Saving the accuracy result of the training
INFO 2017-08-08 12:34:24,791 - Number of layers: 3
INFO 2017-08-08 12:34:24,791 - Number of neurons: 1024
INFO 2017-08-08 12:34:24,791 - Activation: sigmoid
INFO 2017-08-08 12:34:24,791 - Optimizer: adamax
INFO 2017-08-08 12:34:24,791 - Dropout: 0.15
INFO 2017-08-08 12:50:50,030 - Acc @ Training: 0%
INFO 2017-08-08 12:50:50,030 - Acc @ Testing: 54.95%
INFO 2017-08-08 12:50:50,030 - --------------------------------------------------------
INFO 2017-08-08 12:50:50,030 - Saving the accuracy result of the training
INFO 2017-08-08 12:50:50,030 - Number of layers: 3
INFO 2017-08-08 12:50:50,030 - Number of neurons: 1024
INFO 2017-08-08 12:50:50,030 - Activation: relu
INFO 2017-08-08 12:50:50,030 - Optimizer: adamax
INFO 2017-08-08 12:50:50,030 - Dropout: 0.15
INFO 2017-08-08 13:04:30,016 - Acc @ Training: 0%
INFO 2017-08-08 13:04:30,016 - Acc @ Testing: 52.56%
INFO 2017-08-08 13:04:30,017 - --------------------------------------------------------
INFO 2017-08-08 13:04:30,017 - Saving the accuracy result of the training
INFO 2017-08-08 13:04:30,017 - Number of layers: 3
INFO 2017-08-08 13:04:30,017 - Number of neurons: 1024
INFO 2017-08-08 13:04:30,017 - Activation: sigmoid
INFO 2017-08-08 13:04:30,017 - Optimizer: adamax
INFO 2017-08-08 13:04:30,017 - Dropout: 0.15
INFO 2017-08-08 13:20:52,511 - Acc @ Training: 0%
INFO 2017-08-08 13:20:52,511 - Acc @ Testing: 54.61%
INFO 2017-08-08 13:20:52,511 - --------------------------------------------------------
INFO 2017-08-08 13:20:52,511 - Saving the accuracy result of the training
INFO 2017-08-08 13:20:52,511 - Number of layers: 4
INFO 2017-08-08 13:20:52,511 - Number of neurons: 1024
INFO 2017-08-08 13:20:52,511 - Activation: relu
INFO 2017-08-08 13:20:52,511 - Optimizer: adamax
INFO 2017-08-08 13:20:52,511 - Dropout: 0.1
INFO 2017-08-08 13:33:47,941 - Acc @ Training: 0%
INFO 2017-08-08 13:33:47,941 - Acc @ Testing: 52.0%
INFO 2017-08-08 13:33:47,941 - --------------------------------------------------------
INFO 2017-08-08 13:33:47,941 - Saving the accuracy result of the training
INFO 2017-08-08 13:33:47,941 - Number of layers: 4
INFO 2017-08-08 13:33:47,941 - Number of neurons: 1024
INFO 2017-08-08 13:33:47,941 - Activation: relu
INFO 2017-08-08 13:33:47,941 - Optimizer: adamax
INFO 2017-08-08 13:33:47,941 - Dropout: 0.05
INFO 2017-08-08 13:44:28,002 - Acc @ Training: 0%
INFO 2017-08-08 13:44:28,002 - Acc @ Testing: 50.85%
INFO 2017-08-08 13:44:28,003 - --------------------------------------------------------
INFO 2017-08-08 13:44:28,003 - Saving the accuracy result of the training
INFO 2017-08-08 13:44:28,003 - Number of layers: 3
INFO 2017-08-08 13:44:28,003 - Number of neurons: 256
INFO 2017-08-08 13:44:28,003 - Activation: sigmoid
INFO 2017-08-08 13:44:28,003 - Optimizer: adamax
INFO 2017-08-08 13:44:28,003 - Dropout: 0.15
INFO 2017-08-08 13:50:20,193 - Acc @ Training: 0%
INFO 2017-08-08 13:50:20,194 - Acc @ Testing: 54.1%
INFO 2017-08-08 13:50:20,194 - --------------------------------------------------------
INFO 2017-08-08 13:50:20,194 - Saving the accuracy result of the training
INFO 2017-08-08 13:50:20,194 - Number of layers: 4
INFO 2017-08-08 13:50:20,194 - Number of neurons: 1024
INFO 2017-08-08 13:50:20,194 - Activation: relu
INFO 2017-08-08 13:50:20,194 - Optimizer: adamax
INFO 2017-08-08 13:50:20,194 - Dropout: 0.05
INFO 2017-08-08 13:58:35,645 - Acc @ Training: 0%
INFO 2017-08-08 13:58:35,645 - Acc @ Testing: 52.56%
INFO 2017-08-08 13:58:35,645 - --------------------------------------------------------
INFO 2017-08-08 13:58:35,645 - Saving the accuracy result of the training
INFO 2017-08-08 13:58:35,645 - Number of layers: 3
INFO 2017-08-08 13:58:35,645 - Number of neurons: 1024
INFO 2017-08-08 13:58:35,645 - Activation: sigmoid
INFO 2017-08-08 13:58:35,645 - Optimizer: adamax
INFO 2017-08-08 13:58:35,645 - Dropout: 0.05
INFO 2017-08-08 14:10:26,835 - Acc @ Training: 0%
INFO 2017-08-08 14:10:26,835 - Acc @ Testing: 54.06%
INFO 2017-08-08 14:10:26,835 - --------------------------------------------------------
INFO 2017-08-08 14:10:26,835 - Saving the accuracy result of the training
INFO 2017-08-08 14:10:26,835 - Number of layers: 3
INFO 2017-08-08 14:10:26,836 - Number of neurons: 1024
INFO 2017-08-08 14:10:26,836 - Activation: sigmoid
INFO 2017-08-08 14:10:26,836 - Optimizer: adamax
INFO 2017-08-08 14:10:26,836 - Dropout: 0.15
INFO 2017-08-08 14:29:34,594 - Acc @ Training: 0%
INFO 2017-08-08 14:29:34,594 - Acc @ Testing: 56.42%
INFO 2017-08-08 14:29:34,594 - --------------------------------------------------------
INFO 2017-08-08 14:29:34,595 - Saving the accuracy result of the training
INFO 2017-08-08 14:29:34,595 - Number of layers: 4
INFO 2017-08-08 14:29:34,595 - Number of neurons: 1024
INFO 2017-08-08 14:29:34,595 - Activation: relu
INFO 2017-08-08 14:29:34,595 - Optimizer: adamax
INFO 2017-08-08 14:29:34,595 - Dropout: 0.1
INFO 2017-08-08 14:43:57,228 - Acc @ Training: 0%
INFO 2017-08-08 14:43:57,228 - Acc @ Testing: 52.43%
INFO 2017-08-08 14:43:57,228 - --------------------------------------------------------
INFO 2017-08-08 14:43:57,228 - Saving the accuracy result of the training
INFO 2017-08-08 14:43:57,228 - Number of layers: 3
INFO 2017-08-08 14:43:57,228 - Number of neurons: 256
INFO 2017-08-08 14:43:57,228 - Activation: selu
INFO 2017-08-08 14:43:57,228 - Optimizer: adamax
INFO 2017-08-08 14:43:57,228 - Dropout: 0.15
INFO 2017-08-08 14:47:53,847 - Acc @ Training: 0%
INFO 2017-08-08 14:47:53,848 - Acc @ Testing: 53.24%
INFO 2017-08-08 14:47:53,848 - --------------------------------------------------------
INFO 2017-08-08 14:47:53,848 - Saving the accuracy result of the training
INFO 2017-08-08 14:47:53,848 - Number of layers: 3
INFO 2017-08-08 14:47:53,848 - Number of neurons: 1024
INFO 2017-08-08 14:47:53,848 - Activation: selu
INFO 2017-08-08 14:47:53,848 - Optimizer: adamax
INFO 2017-08-08 14:47:53,848 - Dropout: 0.05
INFO 2017-08-08 14:50:55,663 - Acc @ Training: 0%
INFO 2017-08-08 14:50:55,663 - Acc @ Testing: 10.0%
INFO 2017-08-08 14:50:55,663 - --------------------------------------------------------
INFO 2017-08-08 14:50:55,663 - Saving the accuracy result of the training
INFO 2017-08-08 14:50:55,663 - Number of layers: 3
INFO 2017-08-08 14:50:55,663 - Number of neurons: 1024
INFO 2017-08-08 14:50:55,663 - Activation: relu
INFO 2017-08-08 14:50:55,663 - Optimizer: adamax
INFO 2017-08-08 14:50:55,663 - Dropout: 0.15
INFO 2017-08-08 15:08:11,528 - Acc @ Training: 0%
INFO 2017-08-08 15:08:11,529 - Acc @ Testing: 52.56%
INFO 2017-08-08 15:08:11,529 - --------------------------------------------------------
INFO 2017-08-08 15:08:11,529 - Saving the accuracy result of the training
INFO 2017-08-08 15:08:11,529 - Number of layers: 3
INFO 2017-08-08 15:08:11,529 - Number of neurons: 1024
INFO 2017-08-08 15:08:11,529 - Activation: sigmoid
INFO 2017-08-08 15:08:11,529 - Optimizer: adamax
INFO 2017-08-08 15:08:11,529 - Dropout: 0.15
INFO 2017-08-08 15:24:10,334 - Acc @ Training: 0%
INFO 2017-08-08 15:24:10,334 - Acc @ Testing: 53.76%
INFO 2017-08-08 15:24:10,334 - --------------------------------------------------------
INFO 2017-08-08 15:24:10,334 - Saving the accuracy result of the training
INFO 2017-08-08 15:24:10,334 - Number of layers: 3
INFO 2017-08-08 15:24:10,335 - Number of neurons: 1024
INFO 2017-08-08 15:24:10,335 - Activation: sigmoid
INFO 2017-08-08 15:24:10,335 - Optimizer: adamax
INFO 2017-08-08 15:24:10,335 - Dropout: 0.15
INFO 2017-08-08 15:37:58,092 - Acc @ Training: 0%
INFO 2017-08-08 15:37:58,093 - Acc @ Testing: 53.46%
INFO 2017-08-08 15:37:58,093 - --------------------------------------------------------
INFO 2017-08-08 15:37:58,093 - Generation Average: 51.3035
INFO 2017-08-08 15:37:58,093 - --------------------------------------------------------
INFO 2017-08-08 16:50:36,743 - Cifar10 data retrieved & Processed
INFO 2017-08-08 16:50:36,744 - Starting Proof of Concept
INFO 2017-08-08 16:50:36,744 - Number of layers: [1, 2, 3, 4, 5]
INFO 2017-08-08 16:50:36,744 - Number of neurons: [32, 64, 128, 256, 512, 768, 1024]
INFO 2017-08-08 16:50:36,744 - Activation: ['tanh', 'sigmoid', 'relu', 'elu', 'selu', 'linear']
INFO 2017-08-08 16:50:36,744 - Optimizer: ['sgd', 'adamax', 'rmsprop', 'adagrad', 'adadelta', 'adam', 'nadam']
INFO 2017-08-08 16:50:36,744 - Dropout: [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4]
INFO 2017-08-08 16:50:36,744 - /////////////////////////////////////////////////////
INFO 2017-08-08 16:50:36,745 - Parents: [{'optimizer': 'adamax', 'nb_neurons': 1024, 'activation': 'sigmoid', 'dropout': 0.15, 'nb_layers': 3}, {'optimizer': 'adamax', 'nb_neurons': 1024, 'activation': 'sigmoid', 'dropout': 0.15, 'nb_layers': 3}, {'optimizer': 'adamax', 'nb_neurons': 256, 'activation': 'selu', 'dropout': 0.15, 'nb_layers': 3}, {'optimizer': 'adamax', 'nb_neurons': 1024, 'activation': 'sigmoid', 'dropout': 0.15, 'nb_layers': 3}]
INFO 2017-08-08 16:50:36,745 - *************************************************
INFO 2017-08-08 16:50:36,746 - ------ GEN 5 ------
INFO 2017-08-08 16:50:36,746 - Saving the accuracy result of the training
INFO 2017-08-08 16:50:36,746 - Number of layers: 3
INFO 2017-08-08 16:50:36,746 - Number of neurons: 1024
INFO 2017-08-08 16:50:36,746 - Activation: sigmoid
INFO 2017-08-08 16:50:36,746 - Optimizer: adamax
INFO 2017-08-08 16:50:36,746 - Dropout: 0.15
INFO 2017-08-08 17:09:08,703 - Acc @ Training: 0%
INFO 2017-08-08 17:09:08,709 - Acc @ Testing: 55.63%
INFO 2017-08-08 17:09:08,709 - --------------------------------------------------------
INFO 2017-08-08 17:09:08,709 - Saving the accuracy result of the training
INFO 2017-08-08 17:09:08,709 - Number of layers: 3
INFO 2017-08-08 17:09:08,709 - Number of neurons: 1024
INFO 2017-08-08 17:09:08,709 - Activation: sigmoid
INFO 2017-08-08 17:09:08,709 - Optimizer: adamax
INFO 2017-08-08 17:09:08,709 - Dropout: 0.15
INFO 2017-08-08 17:23:11,113 - Acc @ Training: 0%
INFO 2017-08-08 17:23:11,114 - Acc @ Testing: 54.37%
INFO 2017-08-08 17:23:11,114 - --------------------------------------------------------
INFO 2017-08-08 17:23:11,114 - Saving the accuracy result of the training
INFO 2017-08-08 17:23:11,114 - Number of layers: 4
INFO 2017-08-08 17:23:11,114 - Number of neurons: 256
INFO 2017-08-08 17:23:11,114 - Activation: selu
INFO 2017-08-08 17:23:11,114 - Optimizer: adamax
INFO 2017-08-08 17:23:11,114 - Dropout: 0.15
INFO 2017-08-08 17:28:43,385 - Acc @ Training: 0%
INFO 2017-08-08 17:28:43,385 - Acc @ Testing: 52.87%
INFO 2017-08-08 17:28:43,385 - --------------------------------------------------------
INFO 2017-08-08 17:28:43,385 - Saving the accuracy result of the training
INFO 2017-08-08 17:28:43,385 - Number of layers: 3
INFO 2017-08-08 17:28:43,385 - Number of neurons: 1024
INFO 2017-08-08 17:28:43,385 - Activation: sigmoid
INFO 2017-08-08 17:28:43,385 - Optimizer: adamax
INFO 2017-08-08 17:28:43,385 - Dropout: 0.1
INFO 2017-08-08 17:46:19,007 - Acc @ Training: 0%
INFO 2017-08-08 17:46:19,008 - Acc @ Testing: 55.0%
INFO 2017-08-08 17:46:19,008 - --------------------------------------------------------
INFO 2017-08-08 17:46:19,008 - Saving the accuracy result of the training
INFO 2017-08-08 17:46:19,008 - Number of layers: 3
INFO 2017-08-08 17:46:19,008 - Number of neurons: 1024
INFO 2017-08-08 17:46:19,008 - Activation: sigmoid
INFO 2017-08-08 17:46:19,008 - Optimizer: adamax
INFO 2017-08-08 17:46:19,008 - Dropout: 0.15
INFO 2017-08-08 18:03:10,329 - Acc @ Training: 0%
INFO 2017-08-08 18:03:10,329 - Acc @ Testing: 54.91%
INFO 2017-08-08 18:03:10,329 - --------------------------------------------------------
INFO 2017-08-08 18:03:10,329 - Saving the accuracy result of the training
INFO 2017-08-08 18:03:10,329 - Number of layers: 3
INFO 2017-08-08 18:03:10,329 - Number of neurons: 1024
INFO 2017-08-08 18:03:10,329 - Activation: sigmoid
INFO 2017-08-08 18:03:10,329 - Optimizer: adamax
INFO 2017-08-08 18:03:10,329 - Dropout: 0.15
INFO 2017-08-08 18:22:05,884 - Acc @ Training: 0%
INFO 2017-08-08 18:22:05,885 - Acc @ Testing: 55.44%
INFO 2017-08-08 18:22:05,885 - --------------------------------------------------------
INFO 2017-08-08 18:22:05,885 - Saving the accuracy result of the training
INFO 2017-08-08 18:22:05,885 - Number of layers: 3
INFO 2017-08-08 18:22:05,885 - Number of neurons: 256
INFO 2017-08-08 18:22:05,885 - Activation: sigmoid
INFO 2017-08-08 18:22:05,885 - Optimizer: adamax
INFO 2017-08-08 18:22:05,885 - Dropout: 0.1
INFO 2017-08-08 18:25:48,221 - Acc @ Training: 0%
INFO 2017-08-08 18:25:48,221 - Acc @ Testing: 51.06%
INFO 2017-08-08 18:25:48,221 - --------------------------------------------------------
INFO 2017-08-08 18:25:48,221 - Saving the accuracy result of the training
INFO 2017-08-08 18:25:48,221 - Number of layers: 3
INFO 2017-08-08 18:25:48,221 - Number of neurons: 1024
INFO 2017-08-08 18:25:48,221 - Activation: sigmoid
INFO 2017-08-08 18:25:48,221 - Optimizer: adamax
INFO 2017-08-08 18:25:48,221 - Dropout: 0.1
INFO 2017-08-08 18:39:03,151 - Acc @ Training: 0%
INFO 2017-08-08 18:39:03,151 - Acc @ Testing: 54.91%
INFO 2017-08-08 18:39:03,151 - --------------------------------------------------------
INFO 2017-08-08 18:39:03,151 - Saving the accuracy result of the training
INFO 2017-08-08 18:39:03,151 - Number of layers: 3
INFO 2017-08-08 18:39:03,151 - Number of neurons: 256
INFO 2017-08-08 18:39:03,151 - Activation: sigmoid
INFO 2017-08-08 18:39:03,151 - Optimizer: adamax
INFO 2017-08-08 18:39:03,151 - Dropout: 0.1
INFO 2017-08-08 18:42:44,251 - Acc @ Training: 0%
INFO 2017-08-08 18:42:44,251 - Acc @ Testing: 52.57%
INFO 2017-08-08 18:42:44,251 - --------------------------------------------------------
INFO 2017-08-08 18:42:44,251 - Saving the accuracy result of the training
INFO 2017-08-08 18:42:44,251 - Number of layers: 4
INFO 2017-08-08 18:42:44,251 - Number of neurons: 256
INFO 2017-08-08 18:42:44,251 - Activation: selu
INFO 2017-08-08 18:42:44,251 - Optimizer: adamax
INFO 2017-08-08 18:42:44,251 - Dropout: 0.15
INFO 2017-08-08 18:48:45,514 - Acc @ Training: 0%
INFO 2017-08-08 18:48:45,514 - Acc @ Testing: 54.58%
INFO 2017-08-08 18:48:45,514 - --------------------------------------------------------
INFO 2017-08-08 18:48:45,514 - Saving the accuracy result of the training
INFO 2017-08-08 18:48:45,514 - Number of layers: 3
INFO 2017-08-08 18:48:45,514 - Number of neurons: 1024
INFO 2017-08-08 18:48:45,514 - Activation: sigmoid
INFO 2017-08-08 18:48:45,515 - Optimizer: adamax
INFO 2017-08-08 18:48:45,515 - Dropout: 0.15
INFO 2017-08-08 19:10:36,182 - Acc @ Training: 0%
INFO 2017-08-08 19:10:36,182 - Acc @ Testing: 56.42%
INFO 2017-08-08 19:10:36,182 - --------------------------------------------------------
INFO 2017-08-08 19:10:36,182 - Saving the accuracy result of the training
INFO 2017-08-08 19:10:36,182 - Number of layers: 3
INFO 2017-08-08 19:10:36,182 - Number of neurons: 1024
INFO 2017-08-08 19:10:36,182 - Activation: sigmoid
INFO 2017-08-08 19:10:36,182 - Optimizer: adamax
INFO 2017-08-08 19:10:36,182 - Dropout: 0.15
INFO 2017-08-08 19:27:45,324 - Acc @ Training: 0%
INFO 2017-08-08 19:27:45,324 - Acc @ Testing: 54.05%
INFO 2017-08-08 19:27:45,324 - --------------------------------------------------------
INFO 2017-08-08 19:27:45,324 - Saving the accuracy result of the training
INFO 2017-08-08 19:27:45,324 - Number of layers: 3
INFO 2017-08-08 19:27:45,324 - Number of neurons: 1024
INFO 2017-08-08 19:27:45,324 - Activation: sigmoid
INFO 2017-08-08 19:27:45,324 - Optimizer: adamax
INFO 2017-08-08 19:27:45,324 - Dropout: 0.15
INFO 2017-08-08 19:46:02,637 - Acc @ Training: 0%
INFO 2017-08-08 19:46:02,637 - Acc @ Testing: 54.66%
INFO 2017-08-08 19:46:02,637 - --------------------------------------------------------
INFO 2017-08-08 19:46:02,637 - Saving the accuracy result of the training
INFO 2017-08-08 19:46:02,637 - Number of layers: 3
INFO 2017-08-08 19:46:02,637 - Number of neurons: 1024
INFO 2017-08-08 19:46:02,637 - Activation: sigmoid
INFO 2017-08-08 19:46:02,637 - Optimizer: adamax
INFO 2017-08-08 19:46:02,638 - Dropout: 0.15
INFO 2017-08-08 19:56:02,887 - Acc @ Training: 0%
INFO 2017-08-08 19:56:02,887 - Acc @ Testing: 51.41%
INFO 2017-08-08 19:56:02,887 - --------------------------------------------------------
INFO 2017-08-08 19:56:02,887 - Saving the accuracy result of the training
INFO 2017-08-08 19:56:02,887 - Number of layers: 4
INFO 2017-08-08 19:56:02,887 - Number of neurons: 256
INFO 2017-08-08 19:56:02,887 - Activation: selu
INFO 2017-08-08 19:56:02,887 - Optimizer: adamax
INFO 2017-08-08 19:56:02,887 - Dropout: 0.1
INFO 2017-08-08 19:59:41,101 - Acc @ Training: 0%
INFO 2017-08-08 19:59:41,102 - Acc @ Testing: 53.08%
INFO 2017-08-08 19:59:41,102 - --------------------------------------------------------
INFO 2017-08-08 19:59:41,102 - Saving the accuracy result of the training
INFO 2017-08-08 19:59:41,102 - Number of layers: 3
INFO 2017-08-08 19:59:41,102 - Number of neurons: 1024
INFO 2017-08-08 19:59:41,102 - Activation: sigmoid
INFO 2017-08-08 19:59:41,102 - Optimizer: adamax
INFO 2017-08-08 19:59:41,102 - Dropout: 0.15
INFO 2017-08-08 20:18:40,760 - Acc @ Training: 0%
INFO 2017-08-08 20:18:40,760 - Acc @ Testing: 54.86%
INFO 2017-08-08 20:18:40,760 - --------------------------------------------------------
INFO 2017-08-08 20:18:40,760 - Saving the accuracy result of the training
INFO 2017-08-08 20:18:40,760 - Number of layers: 3
INFO 2017-08-08 20:18:40,760 - Number of neurons: 1024
INFO 2017-08-08 20:18:40,760 - Activation: sigmoid
INFO 2017-08-08 20:18:40,760 - Optimizer: adamax
INFO 2017-08-08 20:18:40,760 - Dropout: 0.15
INFO 2017-08-08 20:36:39,328 - Acc @ Training: 0%
INFO 2017-08-08 20:36:39,328 - Acc @ Testing: 55.69%
INFO 2017-08-08 20:36:39,328 - --------------------------------------------------------
INFO 2017-08-08 20:36:39,328 - Saving the accuracy result of the training
INFO 2017-08-08 20:36:39,328 - Number of layers: 4
INFO 2017-08-08 20:36:39,328 - Number of neurons: 1024
INFO 2017-08-08 20:36:39,328 - Activation: selu
INFO 2017-08-08 20:36:39,328 - Optimizer: adamax
INFO 2017-08-08 20:36:39,328 - Dropout: 0.15
INFO 2017-08-08 20:40:10,324 - Acc @ Training: 0%
INFO 2017-08-08 20:40:10,324 - Acc @ Testing: 10.0%
INFO 2017-08-08 20:40:10,324 - --------------------------------------------------------
INFO 2017-08-08 20:40:10,324 - Saving the accuracy result of the training
INFO 2017-08-08 20:40:10,324 - Number of layers: 3
INFO 2017-08-08 20:40:10,324 - Number of neurons: 1024
INFO 2017-08-08 20:40:10,324 - Activation: sigmoid
INFO 2017-08-08 20:40:10,324 - Optimizer: adamax
INFO 2017-08-08 20:40:10,324 - Dropout: 0.15
